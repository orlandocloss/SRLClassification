{
    "version": "1.0",
    "description": "Semantic Role Labeling Challenge Dataset",
    "capabilities": {
        "distance": {
            "MFT": {
                "1": [
                    {
                        "tokenized": [
                            "Jack",
                            ",",
                            "despite",
                            "having",
                            "an",
                            "extremely",
                            "busy",
                            "schedule",
                            "and",
                            "numerous",
                            "responsibilities",
                            ",",
                            "fixed",
                            "the",
                            "bike",
                            "."
                        ],
                        "predicate_index": 12,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Mary",
                            ",",
                            "although",
                            "feeling",
                            "under",
                            "the",
                            "weather",
                            ",",
                            "prepared",
                            "dinner",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "My",
                            "neighbor",
                            ",",
                            "who",
                            "recently",
                            "moved",
                            "in",
                            ",",
                            "mowed",
                            "the",
                            "lawn",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "teacher",
                            ",",
                            "after",
                            "grading",
                            "a",
                            "mountain",
                            "of",
                            "papers",
                            ",",
                            "explained",
                            "the",
                            "lesson",
                            "."
                        ],
                        "predicate_index": 10,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Bob",
                            ",",
                            "having",
                            "finished",
                            "his",
                            "homework",
                            "early",
                            ",",
                            "watched",
                            "TV",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Alice",
                            ",",
                            "after",
                            "a",
                            "long",
                            "day",
                            "at",
                            "work",
                            ",",
                            "cooked",
                            "pasta",
                            "."
                        ],
                        "predicate_index": 9,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "cat",
                            ",",
                            "briefly",
                            "startled",
                            "by",
                            "a",
                            "noise",
                            ",",
                            "chased",
                            "the",
                            "mouse",
                            "."
                        ],
                        "predicate_index": 9,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sam",
                            ",",
                            "although",
                            "feeling",
                            "a",
                            "bit",
                            "tired",
                            ",",
                            "completed",
                            "the",
                            "project",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jennifer",
                            ",",
                            "with",
                            "a",
                            "smile",
                            "on",
                            "her",
                            "face",
                            ",",
                            "answered",
                            "the",
                            "question",
                            "."
                        ],
                        "predicate_index": 9,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "dog",
                            ",",
                            "after",
                            "a",
                            "quick",
                            "nap",
                            ",",
                            "barked",
                            "at",
                            "the",
                            "mailman",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "George",
                            ",",
                            "after",
                            "reading",
                            "an",
                            "interesting",
                            "article",
                            ",",
                            "wrote",
                            "a",
                            "summary",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Emily",
                            ",",
                            "despite",
                            "the",
                            "chilly",
                            "weather",
                            ",",
                            "enjoyed",
                            "the",
                            "picnic",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Tom",
                            ",",
                            "having",
                            "overcome",
                            "many",
                            "obstacles",
                            ",",
                            "succeeded",
                            "in",
                            "his",
                            "plan",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sophia",
                            ",",
                            "with",
                            "great",
                            "enthusiasm",
                            ",",
                            "organized",
                            "the",
                            "event",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Liam",
                            ",",
                            "although",
                            "initially",
                            "hesitant",
                            ",",
                            "joined",
                            "the",
                            "meeting",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Olivia",
                            ",",
                            "after",
                            "a",
                            "long",
                            "journey",
                            ",",
                            "arrived",
                            "at",
                            "the",
                            "station",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Noah",
                            ",",
                            "with",
                            "unexpected",
                            "determination",
                            ",",
                            "fixed",
                            "the",
                            "broken",
                            "computer",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ava",
                            ",",
                            "despite",
                            "the",
                            "heavy",
                            "rain",
                            ",",
                            "completed",
                            "her",
                            "assignment",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "William",
                            ",",
                            "after",
                            "taking",
                            "a",
                            "short",
                            "break",
                            ",",
                            "resumed",
                            "his",
                            "work",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Isabella",
                            ",",
                            "with",
                            "a",
                            "quick",
                            "glance",
                            ",",
                            "noticed",
                            "the",
                            "error",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jennifer",
                            ",",
                            "after",
                            "reading",
                            "the",
                            "report",
                            ",",
                            "summarized",
                            "the",
                            "findings",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ethan",
                            ",",
                            "despite",
                            "feeling",
                            "unwell",
                            ",",
                            "skipped",
                            "lunch",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Mia",
                            ",",
                            "after",
                            "watching",
                            "a",
                            "documentary",
                            ",",
                            "admired",
                            "the",
                            "artwork",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Logan",
                            ",",
                            "with",
                            "a",
                            "burst",
                            "of",
                            "energy",
                            ",",
                            "ran",
                            "the",
                            "marathon",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Amelia",
                            ",",
                            "although",
                            "distracted",
                            "by",
                            "a",
                            "phone",
                            "call",
                            ",",
                            "finished",
                            "her",
                            "report",
                            "."
                        ],
                        "predicate_index": 9,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Lucas",
                            ",",
                            "after",
                            "a",
                            "long",
                            "wait",
                            ",",
                            "received",
                            "his",
                            "package",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Charlotte",
                            ",",
                            "with",
                            "considerable",
                            "effort",
                            ",",
                            "assembled",
                            "the",
                            "furniture",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Henry",
                            ",",
                            "despite",
                            "the",
                            "noise",
                            ",",
                            "concentrated",
                            "on",
                            "his",
                            "work",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Victoria",
                            ",",
                            "after",
                            "a",
                            "brief",
                            "pause",
                            ",",
                            "answered",
                            "the",
                            "call",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Daniel",
                            ",",
                            "with",
                            "unexpected",
                            "charm",
                            ",",
                            "won",
                            "the",
                            "debate",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Grace",
                            ",",
                            "although",
                            "feeling",
                            "nervous",
                            ",",
                            "delivered",
                            "the",
                            "speech",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Michael",
                            ",",
                            "after",
                            "a",
                            "quick",
                            "shower",
                            ",",
                            "left",
                            "the",
                            "house",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Emma",
                            ",",
                            "with",
                            "little",
                            "hesitation",
                            ",",
                            "accepted",
                            "the",
                            "offer",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "David",
                            ",",
                            "despite",
                            "his",
                            "fear",
                            "of",
                            "heights",
                            ",",
                            "climbed",
                            "the",
                            "tower",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Olivia",
                            ",",
                            "after",
                            "studying",
                            "the",
                            "map",
                            ",",
                            "navigated",
                            "the",
                            "maze",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "William",
                            ",",
                            "with",
                            "focused",
                            "determination",
                            ",",
                            "solved",
                            "the",
                            "puzzle",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Isabella",
                            ",",
                            "although",
                            "overwhelmed",
                            "by",
                            "information",
                            ",",
                            "understood",
                            "the",
                            "concept",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "James",
                            ",",
                            "after",
                            "reading",
                            "the",
                            "instructions",
                            ",",
                            "built",
                            "the",
                            "model",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sofia",
                            ",",
                            "with",
                            "great",
                            "care",
                            ",",
                            "wrapped",
                            "the",
                            "gift",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Benjamin",
                            ",",
                            "despite",
                            "encountering",
                            "obstacles",
                            ",",
                            "completed",
                            "the",
                            "race",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Mia",
                            ",",
                            "after",
                            "a",
                            "long",
                            "discussion",
                            ",",
                            "revised",
                            "the",
                            "proposal",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Alexander",
                            ",",
                            "with",
                            "a",
                            "burst",
                            "of",
                            "inspiration",
                            ",",
                            "designed",
                            "the",
                            "logo",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Abigail",
                            ",",
                            "although",
                            "facing",
                            "many",
                            "challenges",
                            ",",
                            "improved",
                            "the",
                            "system",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Joseph",
                            ",",
                            "after",
                            "a",
                            "brief",
                            "rest",
                            ",",
                            "resumed",
                            "his",
                            "studies",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ella",
                            ",",
                            "with",
                            "careful",
                            "planning",
                            ",",
                            "organized",
                            "the",
                            "schedule",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Liam",
                            ",",
                            "despite",
                            "the",
                            "chaotic",
                            "environment",
                            ",",
                            "focused",
                            "on",
                            "the",
                            "task",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Chloe",
                            ",",
                            "after",
                            "taking",
                            "notes",
                            ",",
                            "summarized",
                            "the",
                            "lecture",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Daniel",
                            ",",
                            "with",
                            "a",
                            "quick",
                            "decision",
                            ",",
                            "opted",
                            "for",
                            "the",
                            "red",
                            "option",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ava",
                            ",",
                            "although",
                            "initially",
                            "reluctant",
                            ",",
                            "joined",
                            "the",
                            "committee",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Matthew",
                            ",",
                            "after",
                            "hearing",
                            "the",
                            "news",
                            ",",
                            "reacted",
                            "quickly",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Harper",
                            ",",
                            "with",
                            "an",
                            "air",
                            "of",
                            "confidence",
                            ",",
                            "led",
                            "the",
                            "team",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Evelyn",
                            ",",
                            "despite",
                            "the",
                            "challenges",
                            ",",
                            "pursued",
                            "her",
                            "dream",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Oliver",
                            ",",
                            "after",
                            "a",
                            "detailed",
                            "briefing",
                            ",",
                            "executed",
                            "the",
                            "plan",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Scarlett",
                            ",",
                            "with",
                            "a",
                            "clear",
                            "vision",
                            ",",
                            "reformed",
                            "the",
                            "policy",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Caleb",
                            ",",
                            "despite",
                            "the",
                            "setbacks",
                            ",",
                            "pursued",
                            "his",
                            "goal",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Chloe",
                            ",",
                            "after",
                            "receiving",
                            "feedback",
                            ",",
                            "refined",
                            "the",
                            "proposal",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Samuel",
                            ",",
                            "with",
                            "renewed",
                            "energy",
                            ",",
                            "tackled",
                            "the",
                            "challenge",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Lila",
                            ",",
                            "despite",
                            "the",
                            "complications",
                            ",",
                            "solved",
                            "the",
                            "puzzle",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Owen",
                            ",",
                            "after",
                            "a",
                            "moment",
                            "of",
                            "hesitation",
                            ",",
                            "accepted",
                            "the",
                            "invitation",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Hannah",
                            ",",
                            "with",
                            "a",
                            "curious",
                            "mind",
                            ",",
                            "explored",
                            "the",
                            "concept",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ryan",
                            ",",
                            "although",
                            "overwhelmed",
                            "by",
                            "details",
                            ",",
                            "managed",
                            "the",
                            "project",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Zoe",
                            ",",
                            "after",
                            "a",
                            "long",
                            "discussion",
                            ",",
                            "formulated",
                            "the",
                            "idea",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Christopher",
                            ",",
                            "with",
                            "a",
                            "determined",
                            "spirit",
                            ",",
                            "initiated",
                            "the",
                            "process",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Natalie",
                            ",",
                            "despite",
                            "the",
                            "complexity",
                            ",",
                            "solved",
                            "the",
                            "equation",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Aaron",
                            ",",
                            "after",
                            "careful",
                            "consideration",
                            ",",
                            "chose",
                            "the",
                            "red",
                            "option",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Lydia",
                            ",",
                            "with",
                            "unwavering",
                            "focus",
                            ",",
                            "completed",
                            "the",
                            "test",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Brandon",
                            ",",
                            "despite",
                            "numerous",
                            "interruptions",
                            ",",
                            "finished",
                            "his",
                            "work",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Madison",
                            ",",
                            "after",
                            "reviewing",
                            "the",
                            "agenda",
                            ",",
                            "started",
                            "the",
                            "meeting",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Dylan",
                            ",",
                            "with",
                            "quiet",
                            "determination",
                            ",",
                            "solved",
                            "the",
                            "problem",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Aubrey",
                            ",",
                            "despite",
                            "the",
                            "noise",
                            ",",
                            "concentrated",
                            "on",
                            "her",
                            "task",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Christian",
                            ",",
                            "after",
                            "a",
                            "short",
                            "break",
                            ",",
                            "resumed",
                            "his",
                            "training",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Samantha",
                            ",",
                            "with",
                            "a",
                            "deep",
                            "breath",
                            ",",
                            "began",
                            "the",
                            "lecture",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Isaac",
                            ",",
                            "although",
                            "uncertain",
                            "at",
                            "first",
                            ",",
                            "clarified",
                            "his",
                            "doubts",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Victoria",
                            ",",
                            "after",
                            "a",
                            "quick",
                            "review",
                            ",",
                            "corrected",
                            "the",
                            "error",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Nicholas",
                            ",",
                            "with",
                            "unwavering",
                            "resolve",
                            ",",
                            "completed",
                            "the",
                            "assignment",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ella",
                            ",",
                            "despite",
                            "the",
                            "long",
                            "day",
                            ",",
                            "enjoyed",
                            "the",
                            "concert",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Robert",
                            ",",
                            "after",
                            "a",
                            "thoughtful",
                            "pause",
                            ",",
                            "summarized",
                            "the",
                            "discussion",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Scarlett",
                            ",",
                            "with",
                            "a",
                            "hint",
                            "of",
                            "excitement",
                            ",",
                            "started",
                            "the",
                            "game",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Isaiah",
                            ",",
                            "despite",
                            "the",
                            "early",
                            "morning",
                            "chill",
                            ",",
                            "jogged",
                            "around",
                            "the",
                            "park",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ariana",
                            ",",
                            "after",
                            "reviewing",
                            "her",
                            "performance",
                            ",",
                            "adjusted",
                            "her",
                            "strategy",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Adam",
                            ",",
                            "with",
                            "a",
                            "focused",
                            "mind",
                            ",",
                            "solved",
                            "the",
                            "complex",
                            "puzzle",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Landon",
                            ",",
                            "although",
                            "tired",
                            "from",
                            "work",
                            ",",
                            "planned",
                            "the",
                            "weekend",
                            "outing",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Zachary",
                            ",",
                            "after",
                            "a",
                            "long",
                            "pause",
                            ",",
                            "concluded",
                            "the",
                            "lecture",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sienna",
                            ",",
                            "with",
                            "a",
                            "burst",
                            "of",
                            "insight",
                            ",",
                            "devised",
                            "the",
                            "new",
                            "plan",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Max",
                            ",",
                            "despite",
                            "a",
                            "series",
                            "of",
                            "setbacks",
                            ",",
                            "achieved",
                            "his",
                            "goal",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Hailey",
                            ",",
                            "after",
                            "reading",
                            "the",
                            "instructions",
                            "carefully",
                            ",",
                            "assembled",
                            "the",
                            "model",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    }
                ],
                "2": [
                    {
                        "tokenized": [
                            "John",
                            "kicked",
                            "the",
                            "ball",
                            "and",
                            "scored",
                            "a",
                            "goal",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Alice",
                            "painted",
                            "the",
                            "canvas",
                            "and",
                            "sold",
                            "the",
                            "painting",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Robert",
                            "cooked",
                            "dinner",
                            "and",
                            "cleaned",
                            "the",
                            "kitchen",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Mary",
                            "read",
                            "a",
                            "book",
                            "and",
                            "wrote",
                            "a",
                            "review",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sam",
                            "drove",
                            "a",
                            "car",
                            "and",
                            "parked",
                            "it",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Michael",
                            "ran",
                            "a",
                            "marathon",
                            "and",
                            "broke",
                            "his",
                            "record",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Emily",
                            "designed",
                            "a",
                            "logo",
                            "and",
                            "developed",
                            "a",
                            "website",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "David",
                            "fixed",
                            "the",
                            "computer",
                            "and",
                            "upgraded",
                            "the",
                            "software",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sarah",
                            "wrote",
                            "a",
                            "poem",
                            "and",
                            "recited",
                            "it",
                            "at",
                            "the",
                            "event",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Kevin",
                            "played",
                            "the",
                            "guitar",
                            "and",
                            "composed",
                            "a",
                            "song",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jessica",
                            "baked",
                            "a",
                            "cake",
                            "and",
                            "decorated",
                            "it",
                            "beautifully",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Daniel",
                            "repaired",
                            "the",
                            "bike",
                            "and",
                            "polished",
                            "it",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Laura",
                            "organized",
                            "a",
                            "meeting",
                            "and",
                            "took",
                            "detailed",
                            "minutes",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Brian",
                            "conducted",
                            "an",
                            "experiment",
                            "and",
                            "analyzed",
                            "the",
                            "results",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Nicole",
                            "studied",
                            "the",
                            "report",
                            "and",
                            "summarized",
                            "the",
                            "findings",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Mark",
                            "built",
                            "a",
                            "shed",
                            "and",
                            "painted",
                            "it",
                            "red",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Stephanie",
                            "prepared",
                            "lunch",
                            "and",
                            "served",
                            "it",
                            "promptly",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jason",
                            "delivered",
                            "the",
                            "package",
                            "and",
                            "confirmed",
                            "receipt",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Megan",
                            "captured",
                            "a",
                            "photo",
                            "and",
                            "edited",
                            "it",
                            "skillfully",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Aaron",
                            "programmed",
                            "a",
                            "website",
                            "and",
                            "launched",
                            "it",
                            "successfully",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Olivia",
                            "read",
                            "an",
                            "article",
                            "and",
                            "discussed",
                            "it",
                            "with",
                            "her",
                            "colleagues",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ethan",
                            "completed",
                            "the",
                            "assignment",
                            "and",
                            "submitted",
                            "it",
                            "on",
                            "time",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Chloe",
                            "rehearsed",
                            "the",
                            "play",
                            "and",
                            "performed",
                            "it",
                            "on",
                            "stage",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Brandon",
                            "sketched",
                            "a",
                            "design",
                            "and",
                            "refined",
                            "it",
                            "further",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Victoria",
                            "arranged",
                            "the",
                            "flowers",
                            "and",
                            "displayed",
                            "them",
                            "in",
                            "the",
                            "window",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Luke",
                            "researched",
                            "the",
                            "topic",
                            "and",
                            "presented",
                            "his",
                            "findings",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Grace",
                            "baked",
                            "cookies",
                            "and",
                            "shared",
                            "them",
                            "with",
                            "her",
                            "neighbors",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Justin",
                            "cleaned",
                            "the",
                            "office",
                            "and",
                            "organized",
                            "the",
                            "files",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Hannah",
                            "planted",
                            "a",
                            "tree",
                            "and",
                            "watered",
                            "it",
                            "daily",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Andrew",
                            "assembled",
                            "the",
                            "furniture",
                            "and",
                            "positioned",
                            "it",
                            "in",
                            "the",
                            "living",
                            "room",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sophia",
                            "learned",
                            "a",
                            "new",
                            "language",
                            "and",
                            "practiced",
                            "it",
                            "daily",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jacob",
                            "fixed",
                            "the",
                            "leak",
                            "and",
                            "replaced",
                            "the",
                            "old",
                            "pipe",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ava",
                            "designed",
                            "a",
                            "poster",
                            "and",
                            "printed",
                            "it",
                            "for",
                            "the",
                            "event",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Connor",
                            "drafted",
                            "a",
                            "proposal",
                            "and",
                            "submitted",
                            "it",
                            "for",
                            "review",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Zoe",
                            "recorded",
                            "a",
                            "song",
                            "and",
                            "mixed",
                            "it",
                            "with",
                            "digital",
                            "tools",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ryan",
                            "cooked",
                            "pasta",
                            "and",
                            "tossed",
                            "it",
                            "with",
                            "fresh",
                            "vegetables",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Isabella",
                            "arranged",
                            "a",
                            "seminar",
                            "and",
                            "introduced",
                            "the",
                            "speakers",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Noah",
                            "repaired",
                            "his",
                            "bicycle",
                            "and",
                            "rode",
                            "it",
                            "to",
                            "work",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Madison",
                            "prepared",
                            "a",
                            "presentation",
                            "and",
                            "delivered",
                            "it",
                            "confidently",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Liam",
                            "organized",
                            "a",
                            "charity",
                            "event",
                            "and",
                            "raised",
                            "significant",
                            "funds",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ella",
                            "wrote",
                            "a",
                            "short",
                            "story",
                            "and",
                            "published",
                            "it",
                            "online",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Logan",
                            "painted",
                            "a",
                            "portrait",
                            "and",
                            "exhibited",
                            "it",
                            "at",
                            "the",
                            "gallery",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Scarlett",
                            "edited",
                            "a",
                            "video",
                            "and",
                            "uploaded",
                            "it",
                            "to",
                            "her",
                            "channel",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Carter",
                            "composed",
                            "a",
                            "jingle",
                            "and",
                            "recorded",
                            "it",
                            "in",
                            "the",
                            "studio",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Samantha",
                            "led",
                            "the",
                            "workshop",
                            "and",
                            "answered",
                            "participants",
                            "'",
                            "questions",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Tyler",
                            "fixed",
                            "the",
                            "broken",
                            "chair",
                            "and",
                            "reinforced",
                            "its",
                            "legs",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Avery",
                            "rehearsed",
                            "the",
                            "dance",
                            "routine",
                            "and",
                            "performed",
                            "it",
                            "flawlessly",
                            "."
                        ],
                        "predicate_index": 6,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Elijah",
                            "drafted",
                            "a",
                            "letter",
                            "and",
                            "mailed",
                            "it",
                            "to",
                            "his",
                            "friend",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Mia",
                            "reviewed",
                            "the",
                            "contract",
                            "and",
                            "signed",
                            "it",
                            "after",
                            "approval",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Owen",
                            "captured",
                            "a",
                            "video",
                            "and",
                            "shared",
                            "it",
                            "on",
                            "social",
                            "media",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Riley",
                            "wrote",
                            "a",
                            "blog",
                            "post",
                            "and",
                            "published",
                            "it",
                            "on",
                            "his",
                            "website",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Hailey",
                            "organized",
                            "her",
                            "desk",
                            "and",
                            "sorted",
                            "the",
                            "documents",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Isaac",
                            "built",
                            "a",
                            "model",
                            "and",
                            "presented",
                            "it",
                            "at",
                            "the",
                            "science",
                            "fair",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Aria",
                            "practiced",
                            "the",
                            "piano",
                            "and",
                            "performed",
                            "at",
                            "the",
                            "recital",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Julian",
                            "prepared",
                            "a",
                            "speech",
                            "and",
                            "delivered",
                            "it",
                            "at",
                            "the",
                            "conference",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Lydia",
                            "designed",
                            "an",
                            "app",
                            "and",
                            "released",
                            "it",
                            "to",
                            "the",
                            "public",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Evan",
                            "fixed",
                            "the",
                            "car",
                            "and",
                            "drove",
                            "it",
                            "home",
                            "after",
                            "repairs",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Penelope",
                            "organized",
                            "a",
                            "picnic",
                            "and",
                            "invited",
                            "all",
                            "her",
                            "friends",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Gavin",
                            "recorded",
                            "a",
                            "podcast",
                            "and",
                            "uploaded",
                            "it",
                            "to",
                            "his",
                            "channel",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Alice",
                            "studied",
                            "the",
                            "data",
                            "and",
                            "drew",
                            "insightful",
                            "conclusions",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Elena",
                            "cooked",
                            "a",
                            "gourmet",
                            "meal",
                            "and",
                            "served",
                            "it",
                            "at",
                            "the",
                            "dinner",
                            "party",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Adrian",
                            "developed",
                            "a",
                            "game",
                            "and",
                            "launched",
                            "it",
                            "online",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jasmine",
                            "composed",
                            "an",
                            "email",
                            "and",
                            "sent",
                            "it",
                            "to",
                            "her",
                            "team",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Connor",
                            "prepared",
                            "a",
                            "budget",
                            "and",
                            "presented",
                            "it",
                            "to",
                            "the",
                            "board",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Madeline",
                            "took",
                            "photos",
                            "at",
                            "the",
                            "event",
                            "and",
                            "edited",
                            "them",
                            "professionally",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Victor",
                            "fixed",
                            "the",
                            "fence",
                            "and",
                            "repainted",
                            "it",
                            "with",
                            "fresh",
                            "colors",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Lola",
                            "organized",
                            "a",
                            "workshop",
                            "and",
                            "led",
                            "an",
                            "interactive",
                            "session",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Miles",
                            "wrote",
                            "a",
                            "research",
                            "paper",
                            "and",
                            "published",
                            "it",
                            "in",
                            "a",
                            "journal",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sophie",
                            "designed",
                            "a",
                            "brochure",
                            "and",
                            "distributed",
                            "it",
                            "at",
                            "the",
                            "fair",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Dylan",
                            "reformed",
                            "the",
                            "process",
                            "and",
                            "implemented",
                            "new",
                            "guidelines",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Brooke",
                            "cleaned",
                            "the",
                            "garage",
                            "and",
                            "organized",
                            "the",
                            "tools",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Cole",
                            "revised",
                            "the",
                            "manuscript",
                            "and",
                            "submitted",
                            "it",
                            "for",
                            "publication",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Claire",
                            "crafted",
                            "a",
                            "sculpture",
                            "and",
                            "displayed",
                            "it",
                            "at",
                            "the",
                            "museum",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Mason",
                            "prepared",
                            "a",
                            "training",
                            "session",
                            "and",
                            "conducted",
                            "it",
                            "efficiently",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Stella",
                            "recorded",
                            "a",
                            "lecture",
                            "and",
                            "shared",
                            "it",
                            "with",
                            "the",
                            "class",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Eli",
                            "fixed",
                            "the",
                            "leak",
                            "and",
                            "installed",
                            "a",
                            "new",
                            "pipe",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Violet",
                            "arranged",
                            "the",
                            "meeting",
                            "and",
                            "chaired",
                            "it",
                            "effectively",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Zane",
                            "built",
                            "a",
                            "bookshelf",
                            "and",
                            "installed",
                            "it",
                            "in",
                            "his",
                            "office",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ivy",
                            "designed",
                            "a",
                            "logo",
                            "and",
                            "trademarked",
                            "it",
                            "for",
                            "her",
                            "company",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jared",
                            "cooked",
                            "a",
                            "stew",
                            "and",
                            "served",
                            "it",
                            "to",
                            "his",
                            "family",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Nina",
                            "composed",
                            "a",
                            "melody",
                            "and",
                            "performed",
                            "it",
                            "at",
                            "the",
                            "concert",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Silas",
                            "fixed",
                            "the",
                            "roof",
                            "and",
                            "ensured",
                            "the",
                            "house",
                            "was",
                            "dry",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ruby",
                            "edited",
                            "her",
                            "report",
                            "and",
                            "submitted",
                            "it",
                            "before",
                            "the",
                            "deadline",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Max",
                            "organized",
                            "a",
                            "conference",
                            "and",
                            "coordinated",
                            "with",
                            "multiple",
                            "speakers",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sage",
                            "wrote",
                            "an",
                            "article",
                            "and",
                            "had",
                            "it",
                            "featured",
                            "in",
                            "the",
                            "magazine",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Beau",
                            "recorded",
                            "a",
                            "track",
                            "and",
                            "produced",
                            "it",
                            "with",
                            "modern",
                            "software",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Raven",
                            "prepared",
                            "the",
                            "agenda",
                            "and",
                            "distributed",
                            "it",
                            "to",
                            "the",
                            "participants",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Troy",
                            "fixed",
                            "the",
                            "error",
                            "and",
                            "recompiled",
                            "the",
                            "program",
                            "successfully",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Piper",
                            "designed",
                            "a",
                            "website",
                            "and",
                            "optimized",
                            "it",
                            "for",
                            "mobile",
                            "devices",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Lane",
                            "prepared",
                            "a",
                            "portfolio",
                            "and",
                            "showcased",
                            "his",
                            "work",
                            "in",
                            "an",
                            "exhibition",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Adeline",
                            "revised",
                            "the",
                            "policy",
                            "and",
                            "implemented",
                            "the",
                            "changes",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Phoenix",
                            "built",
                            "a",
                            "prototype",
                            "and",
                            "tested",
                            "it",
                            "rigorously",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Iris",
                            "drafted",
                            "a",
                            "contract",
                            "and",
                            "negotiated",
                            "its",
                            "terms",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Levi",
                            "fixed",
                            "the",
                            "error",
                            "and",
                            "updated",
                            "the",
                            "system",
                            "promptly",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Jade",
                            "wrote",
                            "a",
                            "proposal",
                            "and",
                            "secured",
                            "funding",
                            "for",
                            "the",
                            "project",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Ronan",
                            "designed",
                            "a",
                            "system",
                            "and",
                            "integrated",
                            "it",
                            "with",
                            "existing",
                            "tools",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Molly",
                            "compiled",
                            "the",
                            "data",
                            "and",
                            "presented",
                            "a",
                            "comprehensive",
                            "analysis",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Grayson",
                            "fixed",
                            "the",
                            "wiring",
                            "and",
                            "restored",
                            "power",
                            "to",
                            "the",
                            "building",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Peyton",
                            "organized",
                            "a",
                            "seminar",
                            "and",
                            "facilitated",
                            "the",
                            "discussion",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Lola",
                            "revised",
                            "the",
                            "curriculum",
                            "and",
                            "introduced",
                            "innovative",
                            "courses",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 0,
                        "target_SRL": "ARG0"
                    }
                ]
            }
        },
        "spacetemp": {
            "DIR": {
                "1": [
                    {
                        "tokenized1": [
                            "John",
                            "met",
                            "Jack",
                            "on",
                            "Friday",
                            "."
                        ],
                        "tokenized2": [
                            "John",
                            "met",
                            "Jack",
                            "under",
                            "a",
                            "bridge",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 4,
                        "target_index2": 5,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Mark",
                            "delivered",
                            "the",
                            "package",
                            "at",
                            "3",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Mark",
                            "delivered",
                            "the",
                            "package",
                            "at",
                            "the",
                            "post",
                            "office",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Emma",
                            "started",
                            "the",
                            "presentation",
                            "at",
                            "dawn",
                            "."
                        ],
                        "tokenized2": [
                            "Emma",
                            "started",
                            "the",
                            "presentation",
                            "near",
                            "the",
                            "auditorium",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Lucas",
                            "finished",
                            "the",
                            "race",
                            "at",
                            "sunset",
                            "."
                        ],
                        "tokenized2": [
                            "Lucas",
                            "finished",
                            "the",
                            "race",
                            "on",
                            "the",
                            "track",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Olivia",
                            "began",
                            "the",
                            "meeting",
                            "at",
                            "10",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Olivia",
                            "began",
                            "the",
                            "meeting",
                            "at",
                            "the",
                            "conference",
                            "room",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Ethan",
                            "completed",
                            "the",
                            "assignment",
                            "at",
                            "midnight",
                            "."
                        ],
                        "tokenized2": [
                            "Ethan",
                            "completed",
                            "the",
                            "assignment",
                            "in",
                            "the",
                            "library",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Sophia",
                            "started",
                            "the",
                            "project",
                            "at",
                            "dawn",
                            "."
                        ],
                        "tokenized2": [
                            "Sophia",
                            "started",
                            "the",
                            "project",
                            "in",
                            "the",
                            "studio",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Daniel",
                            "submitted",
                            "the",
                            "report",
                            "at",
                            "noon",
                            "."
                        ],
                        "tokenized2": [
                            "Daniel",
                            "submitted",
                            "the",
                            "report",
                            "at",
                            "the",
                            "office",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Ava",
                            "began",
                            "the",
                            "lesson",
                            "at",
                            "sunrise",
                            "."
                        ],
                        "tokenized2": [
                            "Ava",
                            "began",
                            "the",
                            "lesson",
                            "in",
                            "the",
                            "classroom",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Oliver",
                            "finished",
                            "the",
                            "marathon",
                            "at",
                            "dawn",
                            "."
                        ],
                        "tokenized2": [
                            "Oliver",
                            "finished",
                            "the",
                            "marathon",
                            "on",
                            "the",
                            "street",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Mia",
                            "started",
                            "the",
                            "exam",
                            "at",
                            "8",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Mia",
                            "started",
                            "the",
                            "exam",
                            "at",
                            "the",
                            "testing",
                            "center",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Noah",
                            "began",
                            "the",
                            "speech",
                            "at",
                            "7",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Noah",
                            "began",
                            "the",
                            "speech",
                            "in",
                            "the",
                            "auditorium",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Liam",
                            "completed",
                            "the",
                            "workout",
                            "at",
                            "sunrise",
                            "."
                        ],
                        "tokenized2": [
                            "Liam",
                            "completed",
                            "the",
                            "workout",
                            "in",
                            "the",
                            "gym",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Chloe",
                            "started",
                            "the",
                            "exam",
                            "at",
                            "9",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Chloe",
                            "started",
                            "the",
                            "exam",
                            "at",
                            "the",
                            "testing",
                            "facility",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Jacob",
                            "submitted",
                            "the",
                            "proposal",
                            "at",
                            "noon",
                            "."
                        ],
                        "tokenized2": [
                            "Jacob",
                            "submitted",
                            "the",
                            "proposal",
                            "in",
                            "the",
                            "boardroom",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Emily",
                            "started",
                            "the",
                            "lecture",
                            "at",
                            "8",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Emily",
                            "started",
                            "the",
                            "lecture",
                            "in",
                            "the",
                            "classroom",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Anthony",
                            "finished",
                            "the",
                            "report",
                            "at",
                            "midnight",
                            "."
                        ],
                        "tokenized2": [
                            "Anthony",
                            "finished",
                            "the",
                            "report",
                            "in",
                            "the",
                            "office",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Zoe",
                            "started",
                            "the",
                            "song",
                            "at",
                            "sunrise",
                            "."
                        ],
                        "tokenized2": [
                            "Zoe",
                            "started",
                            "the",
                            "song",
                            "at",
                            "the",
                            "concert",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Caleb",
                            "finished",
                            "the",
                            "test",
                            "at",
                            "10",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Caleb",
                            "finished",
                            "the",
                            "test",
                            "in",
                            "the",
                            "examination",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Grace",
                            "began",
                            "the",
                            "seminar",
                            "at",
                            "11",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Grace",
                            "began",
                            "the",
                            "seminar",
                            "at",
                            "the",
                            "conference",
                            "center",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Evan",
                            "completed",
                            "the",
                            "project",
                            "at",
                            "dusk",
                            "."
                        ],
                        "tokenized2": [
                            "Evan",
                            "completed",
                            "the",
                            "project",
                            "on",
                            "the",
                            "rooftop",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Avery",
                            "began",
                            "the",
                            "workout",
                            "at",
                            "6",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Avery",
                            "began",
                            "the",
                            "workout",
                            "in",
                            "the",
                            "gym",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Connor",
                            "started",
                            "the",
                            "task",
                            "at",
                            "2",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Connor",
                            "started",
                            "the",
                            "task",
                            "at",
                            "the",
                            "workshop",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Layla",
                            "finished",
                            "the",
                            "quiz",
                            "at",
                            "3",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Layla",
                            "finished",
                            "the",
                            "quiz",
                            "in",
                            "the",
                            "classroom",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Henry",
                            "began",
                            "the",
                            "lecture",
                            "at",
                            "8",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Henry",
                            "began",
                            "the",
                            "lecture",
                            "at",
                            "the",
                            "university",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Ella",
                            "submitted",
                            "the",
                            "essay",
                            "at",
                            "midnight",
                            "."
                        ],
                        "tokenized2": [
                            "Ella",
                            "submitted",
                            "the",
                            "essay",
                            "in",
                            "the",
                            "study",
                            "room",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Aaron",
                            "began",
                            "the",
                            "assignment",
                            "at",
                            "9",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Aaron",
                            "began",
                            "the",
                            "assignment",
                            "at",
                            "the",
                            "school",
                            "library",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Olivia",
                            "delivered",
                            "the",
                            "lecture",
                            "at",
                            "10",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Olivia",
                            "delivered",
                            "the",
                            "lecture",
                            "in",
                            "the",
                            "seminar",
                            "room",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Caleb",
                            "started",
                            "the",
                            "meeting",
                            "at",
                            "noon",
                            "."
                        ],
                        "tokenized2": [
                            "Caleb",
                            "started",
                            "the",
                            "meeting",
                            "at",
                            "the",
                            "conference",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Evelyn",
                            "finished",
                            "the",
                            "report",
                            "at",
                            "11",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Evelyn",
                            "finished",
                            "the",
                            "report",
                            "in",
                            "the",
                            "office",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Benjamin",
                            "started",
                            "the",
                            "journey",
                            "at",
                            "dawn",
                            "."
                        ],
                        "tokenized2": [
                            "Benjamin",
                            "started",
                            "the",
                            "journey",
                            "on",
                            "the",
                            "highway",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Samantha",
                            "began",
                            "the",
                            "training",
                            "at",
                            "7",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Samantha",
                            "began",
                            "the",
                            "training",
                            "at",
                            "the",
                            "fitness",
                            "center",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Tyler",
                            "completed",
                            "the",
                            "exam",
                            "at",
                            "4",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Tyler",
                            "completed",
                            "the",
                            "exam",
                            "in",
                            "the",
                            "testing",
                            "room",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Isabella",
                            "began",
                            "the",
                            "performance",
                            "at",
                            "dusk",
                            "."
                        ],
                        "tokenized2": [
                            "Isabella",
                            "began",
                            "the",
                            "performance",
                            "on",
                            "the",
                            "stage",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Jack",
                            "finished",
                            "the",
                            "game",
                            "at",
                            "midnight",
                            "."
                        ],
                        "tokenized2": [
                            "Jack",
                            "finished",
                            "the",
                            "game",
                            "at",
                            "the",
                            "arena",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Olivia",
                            "started",
                            "the",
                            "experiment",
                            "at",
                            "dawn",
                            "."
                        ],
                        "tokenized2": [
                            "Olivia",
                            "started",
                            "the",
                            "experiment",
                            "in",
                            "the",
                            "laboratory",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Grace",
                            "ended",
                            "the",
                            "session",
                            "at",
                            "5",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Grace",
                            "ended",
                            "the",
                            "session",
                            "at",
                            "the",
                            "gymnasium",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Ethan",
                            "began",
                            "the",
                            "lesson",
                            "at",
                            "8",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Ethan",
                            "began",
                            "the",
                            "lesson",
                            "in",
                            "the",
                            "lecture",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Chloe",
                            "delivered",
                            "the",
                            "keynote",
                            "at",
                            "9",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Chloe",
                            "delivered",
                            "the",
                            "keynote",
                            "in",
                            "the",
                            "auditorium",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Samuel",
                            "finished",
                            "the",
                            "course",
                            "at",
                            "midnight",
                            "."
                        ],
                        "tokenized2": [
                            "Samuel",
                            "finished",
                            "the",
                            "course",
                            "in",
                            "the",
                            "classroom",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Mia",
                            "started",
                            "the",
                            "project",
                            "at",
                            "7",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Mia",
                            "started",
                            "the",
                            "project",
                            "in",
                            "the",
                            "lab",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Evelyn",
                            "began",
                            "the",
                            "debate",
                            "at",
                            "noon",
                            "."
                        ],
                        "tokenized2": [
                            "Evelyn",
                            "began",
                            "the",
                            "debate",
                            "in",
                            "the",
                            "auditorium",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Julian",
                            "completed",
                            "the",
                            "assignment",
                            "at",
                            "6",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Julian",
                            "completed",
                            "the",
                            "assignment",
                            "in",
                            "the",
                            "study",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Lydia",
                            "began",
                            "the",
                            "research",
                            "at",
                            "dawn",
                            "."
                        ],
                        "tokenized2": [
                            "Lydia",
                            "began",
                            "the",
                            "research",
                            "at",
                            "the",
                            "institute",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Carter",
                            "started",
                            "the",
                            "engine",
                            "at",
                            "8",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Carter",
                            "started",
                            "the",
                            "engine",
                            "in",
                            "the",
                            "garage",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Adrian",
                            "completed",
                            "the",
                            "challenge",
                            "at",
                            "dusk",
                            "."
                        ],
                        "tokenized2": [
                            "Adrian",
                            "completed",
                            "the",
                            "challenge",
                            "on",
                            "the",
                            "field",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Elijah",
                            "began",
                            "the",
                            "lecture",
                            "at",
                            "9",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Elijah",
                            "began",
                            "the",
                            "lecture",
                            "in",
                            "the",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Mason",
                            "finished",
                            "the",
                            "project",
                            "at",
                            "5",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Mason",
                            "finished",
                            "the",
                            "project",
                            "in",
                            "the",
                            "workshop",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Hailey",
                            "began",
                            "the",
                            "training",
                            "at",
                            "6",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Hailey",
                            "began",
                            "the",
                            "training",
                            "at",
                            "the",
                            "gym",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Isaac",
                            "completed",
                            "the",
                            "exam",
                            "at",
                            "10",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Isaac",
                            "completed",
                            "the",
                            "exam",
                            "in",
                            "the",
                            "testing",
                            "center",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Benjamin",
                            "started",
                            "the",
                            "journey",
                            "at",
                            "6",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Benjamin",
                            "started",
                            "the",
                            "journey",
                            "on",
                            "the",
                            "freeway",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Raven",
                            "began",
                            "the",
                            "presentation",
                            "at",
                            "11",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Raven",
                            "began",
                            "the",
                            "presentation",
                            "in",
                            "the",
                            "auditorium",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Gabriel",
                            "submitted",
                            "the",
                            "proposal",
                            "at",
                            "noon",
                            "."
                        ],
                        "tokenized2": [
                            "Gabriel",
                            "submitted",
                            "the",
                            "proposal",
                            "in",
                            "the",
                            "meeting",
                            "room",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Fiona",
                            "started",
                            "the",
                            "workshop",
                            "at",
                            "8",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Fiona",
                            "started",
                            "the",
                            "workshop",
                            "at",
                            "the",
                            "community",
                            "center",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Logan",
                            "began",
                            "the",
                            "assignment",
                            "at",
                            "7",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Logan",
                            "began",
                            "the",
                            "assignment",
                            "in",
                            "the",
                            "study",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Charlotte",
                            "presented",
                            "the",
                            "findings",
                            "at",
                            "10",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Charlotte",
                            "presented",
                            "the",
                            "findings",
                            "in",
                            "the",
                            "conference",
                            "room",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Dominic",
                            "completed",
                            "the",
                            "test",
                            "at",
                            "3",
                            "PM",
                            "."
                        ],
                        "tokenized2": [
                            "Dominic",
                            "completed",
                            "the",
                            "test",
                            "in",
                            "the",
                            "examination",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Rebecca",
                            "started",
                            "the",
                            "seminar",
                            "at",
                            "9",
                            "AM",
                            "."
                        ],
                        "tokenized2": [
                            "Rebecca",
                            "started",
                            "the",
                            "seminar",
                            "in",
                            "the",
                            "lecture",
                            "hall",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 6,
                        "target_index2": 7,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    },
                    {
                        "tokenized1": [
                            "Xavier",
                            "finished",
                            "the",
                            "project",
                            "at",
                            "midnight",
                            "."
                        ],
                        "tokenized2": [
                            "Xavier",
                            "finished",
                            "the",
                            "project",
                            "in",
                            "the",
                            "lab",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 5,
                        "target_index2": 6,
                        "target_SRL1": "ARGM-TMP",
                        "target_SRL2": "ARGM-LOC"
                    }
                ]
            }
        },
        "dativealter": {
            "INV": {
                "1": [
                    {
                        "tokenized1": [
                            "I",
                            "gave",
                            "John",
                            "a",
                            "book",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "gave",
                            "a",
                            "book",
                            "to",
                            "John",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "sent",
                            "Mary",
                            "a",
                            "letter",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "sent",
                            "a",
                            "letter",
                            "to",
                            "Mary",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "offered",
                            "Tom",
                            "a",
                            "ride",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "offered",
                            "a",
                            "ride",
                            "to",
                            "Tom",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "handed",
                            "Mark",
                            "a",
                            "gift",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "handed",
                            "a",
                            "gift",
                            "to",
                            "Mark",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "provided",
                            "Jane",
                            "a",
                            "chance",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "provided",
                            "a",
                            "chance",
                            "to",
                            "Jane",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "Alice",
                            "lent",
                            "Bob",
                            "a",
                            "car",
                            "."
                        ],
                        "tokenized2": [
                            "Alice",
                            "lent",
                            "a",
                            "car",
                            "to",
                            "Bob",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "cooked",
                            "Ann",
                            "a",
                            "meal",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "cooked",
                            "a",
                            "meal",
                            "for",
                            "Ann",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "assigned",
                            "Jack",
                            "a",
                            "task",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "assigned",
                            "a",
                            "task",
                            "to",
                            "Jack",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "awarded",
                            "Kim",
                            "a",
                            "prize",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "awarded",
                            "a",
                            "prize",
                            "to",
                            "Kim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "sent",
                            "Paul",
                            "a",
                            "postcard",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "sent",
                            "a",
                            "postcard",
                            "to",
                            "Paul",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "gave",
                            "Mark",
                            "a",
                            "nod",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "gave",
                            "a",
                            "nod",
                            "to",
                            "Mark",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "offered",
                            "Tom",
                            "a",
                            "seat",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "offered",
                            "a",
                            "seat",
                            "to",
                            "Tom",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "handed",
                            "Eve",
                            "a",
                            "pen",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "handed",
                            "a",
                            "pen",
                            "to",
                            "Eve",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "sent",
                            "Liz",
                            "an",
                            "email",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "sent",
                            "an",
                            "email",
                            "to",
                            "Liz",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "gave",
                            "Sam",
                            "a",
                            "gift",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "gave",
                            "a",
                            "gift",
                            "to",
                            "Sam",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "lent",
                            "Amy",
                            "a",
                            "watch",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "lent",
                            "a",
                            "watch",
                            "to",
                            "Amy",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "sent",
                            "Joe",
                            "a",
                            "note",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "sent",
                            "a",
                            "note",
                            "to",
                            "Joe",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "offered",
                            "Sue",
                            "a",
                            "drink",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "offered",
                            "a",
                            "drink",
                            "to",
                            "Sue",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "handed",
                            "Ben",
                            "a",
                            "key",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "handed",
                            "a",
                            "key",
                            "to",
                            "Ben",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "gave",
                            "Kim",
                            "a",
                            "book",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "gave",
                            "a",
                            "book",
                            "to",
                            "Kim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "sent",
                            "Dan",
                            "a",
                            "card",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "sent",
                            "a",
                            "card",
                            "to",
                            "Dan",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "offered",
                            "Ray",
                            "a",
                            "job",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "offered",
                            "a",
                            "job",
                            "to",
                            "Ray",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "lent",
                            "Tim",
                            "a",
                            "bike",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "lent",
                            "a",
                            "bike",
                            "to",
                            "Tim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "gave",
                            "Max",
                            "a",
                            "chance",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "gave",
                            "a",
                            "chance",
                            "to",
                            "Max",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "sent",
                            "Liz",
                            "a",
                            "package",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "sent",
                            "a",
                            "package",
                            "to",
                            "Liz",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "offered",
                            "Joe",
                            "a",
                            "seat",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "offered",
                            "a",
                            "seat",
                            "to",
                            "Joe",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "handed",
                            "Amy",
                            "a",
                            "letter",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "handed",
                            "a",
                            "letter",
                            "to",
                            "Amy",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "gave",
                            "Bob",
                            "a",
                            "ring",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "gave",
                            "a",
                            "ring",
                            "to",
                            "Bob",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "sent",
                            "Kim",
                            "a",
                            "message",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "sent",
                            "a",
                            "message",
                            "to",
                            "Kim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "gave",
                            "Tim",
                            "a",
                            "book",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "gave",
                            "a",
                            "book",
                            "to",
                            "Tim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "offered",
                            "Sue",
                            "a",
                            "chance",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "offered",
                            "a",
                            "chance",
                            "to",
                            "Sue",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "lent",
                            "Ray",
                            "a",
                            "pen",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "lent",
                            "a",
                            "pen",
                            "to",
                            "Ray",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "gave",
                            "Jan",
                            "a",
                            "smile",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "gave",
                            "a",
                            "smile",
                            "to",
                            "Jan."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "sent",
                            "Lee",
                            "a",
                            "postcard",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "sent",
                            "a",
                            "postcard",
                            "to",
                            "Lee",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "offered",
                            "Ann",
                            "a",
                            "role",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "offered",
                            "a",
                            "role",
                            "to",
                            "Ann",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "gave",
                            "Liz",
                            "a",
                            "ticket",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "gave",
                            "a",
                            "ticket",
                            "to",
                            "Liz",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "sent",
                            "Max",
                            "a",
                            "letter",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "sent",
                            "a",
                            "letter",
                            "to",
                            "Max",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "handed",
                            "Joe",
                            "a",
                            "report",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "handed",
                            "a",
                            "report",
                            "to",
                            "Joe",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "gave",
                            "Sam",
                            "a",
                            "compliment",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "gave",
                            "a",
                            "compliment",
                            "to",
                            "Sam",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "offered",
                            "Kim",
                            "a",
                            "job",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "offered",
                            "a",
                            "job",
                            "to",
                            "Kim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "lent",
                            "Dan",
                            "a",
                            "camera",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "lent",
                            "a",
                            "camera",
                            "to",
                            "Dan",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "sent",
                            "Ray",
                            "a",
                            "postcard",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "sent",
                            "a",
                            "postcard",
                            "to",
                            "Ray",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "gave",
                            "Joe",
                            "a",
                            "chance",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "gave",
                            "a",
                            "chance",
                            "to",
                            "Joe",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "handed",
                            "Kim",
                            "a",
                            "message",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "handed",
                            "a",
                            "message",
                            "to",
                            "Kim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "offered",
                            "Bob",
                            "a",
                            "ride",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "offered",
                            "a",
                            "ride",
                            "to",
                            "Bob",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "gave",
                            "Ann",
                            "a",
                            "note",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "gave",
                            "a",
                            "note",
                            "to",
                            "Ann",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "sent",
                            "Sam",
                            "a",
                            "gift",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "sent",
                            "a",
                            "gift",
                            "to",
                            "Sam",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "He",
                            "lent",
                            "Kim",
                            "a",
                            "book",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "lent",
                            "a",
                            "book",
                            "to",
                            "Kim",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "They",
                            "gave",
                            "Joe",
                            "a",
                            "ticket",
                            "."
                        ],
                        "tokenized2": [
                            "They",
                            "gave",
                            "a",
                            "ticket",
                            "to",
                            "Joe",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "offered",
                            "Liz",
                            "a",
                            "discount",
                            "."
                        ],
                        "tokenized2": [
                            "We",
                            "offered",
                            "a",
                            "discount",
                            "to",
                            "Liz",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 2,
                        "target_index2": 5,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "I",
                            "sent",
                            "my",
                            "friend",
                            "a",
                            "postcard",
                            "."
                        ],
                        "tokenized2": [
                            "I",
                            "sent",
                            "a",
                            "postcard",
                            "to",
                            "my",
                            "friend",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 3,
                        "target_index2": 6,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "handed",
                            "the",
                            "teacher",
                            "a",
                            "pen",
                            "."
                        ],
                        "tokenized2": [
                            "She",
                            "handed",
                            "a",
                            "pen",
                            "to",
                            "the",
                            "teacher",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 3,
                        "target_index2": 6,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "John",
                            "offered",
                            "his",
                            "cousin",
                            "a",
                            "ride",
                            "."
                        ],
                        "tokenized2": [
                            "John",
                            "offered",
                            "a",
                            "ride",
                            "to",
                            "his",
                            "cousin",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 3,
                        "target_index2": 6,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "Anna",
                            "gave",
                            "her",
                            "brother",
                            "a",
                            "hug",
                            "."
                        ],
                        "tokenized2": [
                            "Anna",
                            "gave",
                            "a",
                            "hug",
                            "to",
                            "her",
                            "brother",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 3,
                        "target_index2": 6,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "Mike",
                            "lent",
                            "his",
                            "neighbor",
                            "a",
                            "tool",
                            "."
                        ],
                        "tokenized2": [
                            "Mike",
                            "lent",
                            "a",
                            "tool",
                            "to",
                            "his",
                            "neighbor",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 3,
                        "target_index2": 6,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "Laura",
                            "sent",
                            "her",
                            "colleague",
                            "a",
                            "memo",
                            "."
                        ],
                        "tokenized2": [
                            "Laura",
                            "sent",
                            "a",
                            "memo",
                            "to",
                            "her",
                            "colleague",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 3,
                        "target_index2": 6,
                        "target_SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "David",
                            "offered",
                            "his",
                            "partner",
                            "a",
                            "suggestion",
                            "."
                        ],
                        "tokenized2": [
                            "David",
                            "offered",
                            "a",
                            "suggestion",
                            "to",
                            "his",
                            "partner",
                            "."
                        ],
                        "predicate_index": 1,
                        "target_index1": 3,
                        "target_index2": 6,
                        "target_SRL": "ARG2"
                    }
                ]
            }
        },
        "negation": {
            "MFT": {
                "1": [
                    {
                        "tokenized": [
                            "Jack",
                            "did",
                            "not",
                            "clean",
                            "the",
                            "house",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Maria",
                            "does",
                            "not",
                            "like",
                            "spicy",
                            "food",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "manager",
                            "can",
                            "not",
                            "approve",
                            "the",
                            "proposal",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "He",
                            "will",
                            "not",
                            "attend",
                            "the",
                            "meeting",
                            "tomorrow",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "We",
                            "can",
                            "not",
                            "find",
                            "any",
                            "evidence",
                            "of",
                            "the",
                            "claim",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "dog",
                            "did",
                            "not",
                            "bark",
                            "at",
                            "the",
                            "stranger",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "She",
                            "has",
                            "not",
                            "finished",
                            "her",
                            "homework",
                            "yet",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "team",
                            "will",
                            "not",
                            "win",
                            "the",
                            "championship",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "I",
                            "do",
                            "not",
                            "appreciate",
                            "such",
                            "rudeness",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "They",
                            "did",
                            "not",
                            "complete",
                            "the",
                            "assignment",
                            "on",
                            "time",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Bob",
                            "can",
                            "not",
                            "solve",
                            "the",
                            "puzzle",
                            "alone",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "computer",
                            "will",
                            "not",
                            "restart",
                            "without",
                            "error",
                            "messages",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Lisa",
                            "did",
                            "not",
                            "prepare",
                            "for",
                            "the",
                            "exam",
                            "adequately",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Our",
                            "team",
                            "can",
                            "not",
                            "tolerate",
                            "such",
                            "behavior",
                            "any",
                            "longer",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "He",
                            "does",
                            "not",
                            "enjoy",
                            "reading",
                            "science",
                            "fiction",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "movie",
                            "did",
                            "not",
                            "impress",
                            "the",
                            "critics",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Samantha",
                            "can",
                            "not",
                            "decide",
                            "between",
                            "the",
                            "two",
                            "options",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "I",
                            "did",
                            "not",
                            "receive",
                            "any",
                            "notification",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "chef",
                            "did",
                            "not",
                            "add",
                            "salt",
                            "to",
                            "the",
                            "recipe",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Our",
                            "plan",
                            "will",
                            "not",
                            "work",
                            "if",
                            "we",
                            "rush",
                            "it",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "She",
                            "can",
                            "not",
                            "go",
                            "to",
                            "the",
                            "party",
                            "due",
                            "to",
                            "a",
                            "prior",
                            "commitment",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "report",
                            "does",
                            "not",
                            "reflect",
                            "the",
                            "current",
                            "data",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "We",
                            "do",
                            "not",
                            "require",
                            "a",
                            "receipt",
                            "for",
                            "this",
                            "purchase",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "They",
                            "can",
                            "not",
                            "postpone",
                            "the",
                            "meeting",
                            "any",
                            "further",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "I",
                            "will",
                            "not",
                            "tolerate",
                            "any",
                            "form",
                            "of",
                            "disrespect",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "new",
                            "software",
                            "does",
                            "not",
                            "support",
                            "multiple",
                            "languages",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Mark",
                            "did",
                            "not",
                            "finish",
                            "his",
                            "project",
                            "on",
                            "time",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "cat",
                            "can",
                            "not",
                            "climb",
                            "the",
                            "tall",
                            "tree",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "Our",
                            "vacation",
                            "plans",
                            "did",
                            "not",
                            "include",
                            "any",
                            "outdoor",
                            "activities",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "They",
                            "do",
                            "not",
                            "wish",
                            "to",
                            "participate",
                            "in",
                            "the",
                            "event",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "I",
                            "did",
                            "not",
                            "see",
                            "the",
                            "error",
                            "message",
                            "on",
                            "the",
                            "screen",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "He",
                            "has",
                            "not",
                            "been",
                            "feeling",
                            "well",
                            "lately",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "package",
                            "will",
                            "not",
                            "arrive",
                            "until",
                            "next",
                            "week",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "We",
                            "can",
                            "not",
                            "attend",
                            "the",
                            "concert",
                            "because",
                            "of",
                            "prior",
                            "commitments",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "She",
                            "did",
                            "not",
                            "agree",
                            "with",
                            "the",
                            "proposed",
                            "changes",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "candidate",
                            "can",
                            "not",
                            "win",
                            "the",
                            "election",
                            "without",
                            "support",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "I",
                            "do",
                            "not",
                            "trust",
                            "rumors",
                            "about",
                            "the",
                            "new",
                            "policy",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "They",
                            "have",
                            "not",
                            "completed",
                            "their",
                            "training",
                            "yet",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "robot",
                            "did",
                            "not",
                            "malfunction",
                            "during",
                            "the",
                            "test",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "I",
                            "can",
                            "not",
                            "remember",
                            "the",
                            "last",
                            "time",
                            "I",
                            "visited",
                            "Paris",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "report",
                            "did",
                            "not",
                            "include",
                            "the",
                            "latest",
                            "statistics",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "She",
                            "does",
                            "not",
                            "want",
                            "to",
                            "compromise",
                            "her",
                            "values",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "teacher",
                            "did",
                            "not",
                            "explain",
                            "the",
                            "problem",
                            "clearly",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "I",
                            "can",
                            "not",
                            "accept",
                            "the",
                            "results",
                            "without",
                            "question",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "We",
                            "did",
                            "not",
                            "plan",
                            "to",
                            "extend",
                            "our",
                            "stay",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "They",
                            "will",
                            "not",
                            "invest",
                            "in",
                            "that",
                            "project",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "author",
                            "does",
                            "not",
                            "write",
                            "in",
                            "that",
                            "genre",
                            "anymore",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "We",
                            "can",
                            "not",
                            "believe",
                            "how",
                            "quickly",
                            "time",
                            "flies",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "He",
                            "did",
                            "not",
                            "enjoy",
                            "the",
                            "spicy",
                            "meal",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARGM-NEG"
                    },
                    {
                        "tokenized": [
                            "The",
                            "company",
                            "does",
                            "not",
                            "offer",
                            "refunds",
                            "for",
                            "digital",
                            "purchases",
                            "."
                        ],
                        "predicate_index": 4,
                        "target_index": 3,
                        "target_SRL": "ARGM-NEG"
                    }
                ]
            }
        },
        "head": {
            "MFT": {
                "1": [
                    {
                        "tokenized": [
                            "The",
                            "red",
                            "car",
                            "zoomed",
                            "down",
                            "the",
                            "highway",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Tall",
                            "buildings",
                            "collapsed",
                            "suddenly",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "ancient",
                            "tree",
                            "fell",
                            "in",
                            "the",
                            "storm",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "broken",
                            "vase",
                            "shattered",
                            "on",
                            "the",
                            "floor",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sleepy",
                            "cats",
                            "purred",
                            "softly",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "smiling",
                            "child",
                            "laughed",
                            "happily",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "angry",
                            "teacher",
                            "scolded",
                            "the",
                            "students",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Glistening",
                            "lakes",
                            "reflected",
                            "the",
                            "sky",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "ancient",
                            "book",
                            "captivated",
                            "the",
                            "audience",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "fragile",
                            "sculpture",
                            "survived",
                            "the",
                            "quake",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "vibrant",
                            "painting",
                            "mesmerized",
                            "viewers",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "shattered",
                            "mirror",
                            "lay",
                            "on",
                            "the",
                            "table",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "golden",
                            "key",
                            "unlocked",
                            "the",
                            "door",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "slippery",
                            "slope",
                            "hindered",
                            "progress",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "shiny",
                            "trophy",
                            "gleamed",
                            "under",
                            "the",
                            "spotlight",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "lively",
                            "melody",
                            "enchanted",
                            "the",
                            "crowd",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "frozen",
                            "river",
                            "glistened",
                            "in",
                            "winter",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Dusty",
                            "attics",
                            "reveal",
                            "secrets",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "smooth",
                            "stone",
                            "rolled",
                            "down",
                            "the",
                            "hill",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Sparkling",
                            "rivers",
                            "flowed",
                            "through",
                            "the",
                            "valley",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "brave",
                            "soldier",
                            "marched",
                            "into",
                            "battle",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "tangled",
                            "rope",
                            "hindered",
                            "the",
                            "operation",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Roaring",
                            "lions",
                            "intimidated",
                            "their",
                            "prey",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "curious",
                            "child",
                            "discovered",
                            "a",
                            "path",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "vibrant",
                            "sunset",
                            "lit",
                            "the",
                            "sky",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "gentle",
                            "breeze",
                            "calmed",
                            "the",
                            "crowd",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "cracked",
                            "window",
                            "let",
                            "in",
                            "a",
                            "breeze",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "rusted",
                            "bike",
                            "lay",
                            "in",
                            "the",
                            "yard",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "small",
                            "bird",
                            "chirped",
                            "at",
                            "dawn",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "loud",
                            "bell",
                            "rang",
                            "at",
                            "midnight",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "swift",
                            "runner",
                            "broke",
                            "the",
                            "record",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Frozen",
                            "desserts",
                            "melted",
                            "quickly",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "bright",
                            "lamp",
                            "illuminated",
                            "the",
                            "room",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "gentle",
                            "rain",
                            "soaked",
                            "the",
                            "field",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "ancient",
                            "monument",
                            "stood",
                            "in",
                            "the",
                            "plaza",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "fragrant",
                            "flower",
                            "bloomed",
                            "in",
                            "the",
                            "garden",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Tattered",
                            "shoes",
                            "squeaked",
                            "on",
                            "the",
                            "floor",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "curious",
                            "detective",
                            "solved",
                            "the",
                            "case",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "dusty",
                            "book",
                            "rested",
                            "on",
                            "the",
                            "shelf",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Vibrant",
                            "melodies",
                            "filled",
                            "the",
                            "hall",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "graceful",
                            "dancer",
                            "twirled",
                            "on",
                            "stage",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "rugged",
                            "mountain",
                            "towered",
                            "over",
                            "the",
                            "valley",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Calm",
                            "lakes",
                            "reflected",
                            "the",
                            "scenery",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "nimble",
                            "fox",
                            "darted",
                            "across",
                            "the",
                            "field",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "gleaming",
                            "sword",
                            "cut",
                            "through",
                            "the",
                            "air",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "Tattered",
                            "flags",
                            "waved",
                            "in",
                            "the",
                            "wind",
                            "."
                        ],
                        "predicate_index": 2,
                        "target_index": 1,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "busy",
                            "bee",
                            "buzzed",
                            "around",
                            "the",
                            "garden",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "sleepy",
                            "puppy",
                            "yawned",
                            "in",
                            "the",
                            "afternoon",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "eager",
                            "student",
                            "solved",
                            "an",
                            "equation",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "A",
                            "fragile",
                            "window",
                            "shattered",
                            "during",
                            "the",
                            "storm",
                            "."
                        ],
                        "predicate_index": 3,
                        "target_index": 2,
                        "target_SRL": "ARG0"
                    }
                ],
                "2": [
                    {
                        "tokenized": [
                            "The",
                            "old",
                            ",",
                            "abandoned",
                            "building",
                            "fell",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "bright",
                            ",",
                            "shining",
                            "star",
                            "twinkled",
                            "in",
                            "the",
                            "night",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "large",
                            ",",
                            "rumpled",
                            "suitcase",
                            "arrived",
                            "at",
                            "the",
                            "station",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "green",
                            ",",
                            "overgrown",
                            "garden",
                            "flourished",
                            "in",
                            "spring",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "elegant",
                            ",",
                            "Victorian",
                            "mansion",
                            "stood",
                            "silently",
                            "on",
                            "the",
                            "hill",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "rugged",
                            ",",
                            "weathered",
                            "statue",
                            "crumbled",
                            "under",
                            "pressure",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "tiny",
                            ",",
                            "sparkling",
                            "fountain",
                            "bubbled",
                            "merrily",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "ancient",
                            ",",
                            "mystical",
                            "ruins",
                            "whispered",
                            "secrets",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "busy",
                            ",",
                            "buzzing",
                            "marketplace",
                            "thrived",
                            "during",
                            "the",
                            "festival",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "chilly",
                            ",",
                            "rainy",
                            "evening",
                            "passed",
                            "uneventfully",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "enormous",
                            ",",
                            "intricate",
                            "sculpture",
                            "dominated",
                            "the",
                            "plaza",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "swift",
                            ",",
                            "determined",
                            "runner",
                            "broke",
                            "the",
                            "record",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "gloomy",
                            ",",
                            "stormy",
                            "sky",
                            "darkened",
                            "unexpectedly",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "cheerful",
                            ",",
                            "chirping",
                            "birds",
                            "greeted",
                            "the",
                            "morning",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "sleek",
                            ",",
                            "modern",
                            "smartphone",
                            "revolutionized",
                            "communication",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "quiet",
                            ",",
                            "shadowed",
                            "alley",
                            "concealed",
                            "hidden",
                            "dangers",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "festive",
                            ",",
                            "decorated",
                            "hall",
                            "hosted",
                            "a",
                            "grand",
                            "celebration",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "ancient",
                            ",",
                            "crumbling",
                            "fortress",
                            "withstood",
                            "the",
                            "siege",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "vibrant",
                            ",",
                            "blooming",
                            "garden",
                            "attracted",
                            "many",
                            "butterflies",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "noisy",
                            ",",
                            "bustling",
                            "street",
                            "echoed",
                            "with",
                            "lively",
                            "chatter",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "aged",
                            ",",
                            "tattered",
                            "newspaper",
                            "reported",
                            "old",
                            "news",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "playful",
                            ",",
                            "energetic",
                            "puppy",
                            "chased",
                            "the",
                            "ball",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "refined",
                            ",",
                            "delicate",
                            "china",
                            "impressed",
                            "the",
                            "guests",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "rugged",
                            ",",
                            "worn",
                            "boots",
                            "trudged",
                            "through",
                            "the",
                            "mud",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "pristine",
                            ",",
                            "untouched",
                            "lake",
                            "sparkled",
                            "under",
                            "the",
                            "sun",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "cozy",
                            ",",
                            "inviting",
                            "cottage",
                            "overlooked",
                            "a",
                            "serene",
                            "valley",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "luminous",
                            ",",
                            "radiant",
                            "moon",
                            "illuminated",
                            "the",
                            "dark",
                            "sky",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "chaotic",
                            ",",
                            "disorganized",
                            "files",
                            "confused",
                            "the",
                            "archivist",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "delicate",
                            ",",
                            "handmade",
                            "bracelet",
                            "adorned",
                            "her",
                            "wrist",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "mysterious",
                            ",",
                            "foggy",
                            "landscape",
                            "evoked",
                            "a",
                            "sense",
                            "of",
                            "wonder",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "vibrant",
                            ",",
                            "bustling",
                            "city",
                            "thrived",
                            "at",
                            "night",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "warm",
                            ",",
                            "inviting",
                            "aroma",
                            "filled",
                            "the",
                            "room",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "strong",
                            ",",
                            "sturdy",
                            "bridge",
                            "withstood",
                            "the",
                            "heavy",
                            "traffic",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "intricate",
                            ",",
                            "detailed",
                            "painting",
                            "depicted",
                            "a",
                            "lively",
                            "scene",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "ancient",
                            ",",
                            "weathered",
                            "clock",
                            "chimed",
                            "at",
                            "midnight",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "grand",
                            ",",
                            "opulent",
                            "ballroom",
                            "dazzled",
                            "the",
                            "guests",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "twisted",
                            ",",
                            "tangled",
                            "wires",
                            "disrupted",
                            "the",
                            "signal",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "soft",
                            ",",
                            "glowing",
                            "lights",
                            "brightened",
                            "the",
                            "dim",
                            "corridor",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "rough",
                            ",",
                            "cracked",
                            "pavement",
                            "yielded",
                            "to",
                            "the",
                            "rain",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "shiny",
                            ",",
                            "polished",
                            "mirror",
                            "reflected",
                            "a",
                            "clear",
                            "image",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "fragrant",
                            ",",
                            "blooming",
                            "roses",
                            "filled",
                            "the",
                            "garden",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "massive",
                            ",",
                            "ancient",
                            "pyramid",
                            "dominated",
                            "the",
                            "desert",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "sparkling",
                            ",",
                            "crystal",
                            "-",
                            "clear",
                            "water",
                            "shimmered",
                            "in",
                            "the",
                            "sunlight",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 6,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "delicate",
                            ",",
                            "embroidered",
                            "fabric",
                            "adorned",
                            "the",
                            "elegant",
                            "gown",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "brave",
                            ",",
                            "battle",
                            "-",
                            "hardened",
                            "soldier",
                            "defended",
                            "his",
                            "post",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 6,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "frozen",
                            ",",
                            "icy",
                            "lake",
                            "froze",
                            "solid",
                            "overnight",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "vibrant",
                            ",",
                            "multicolored",
                            "mural",
                            "brightened",
                            "the",
                            "alleyway",
                            "."
                        ],
                        "predicate_index": 5,
                        "target_index": 4,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "intricate",
                            ",",
                            "hand",
                            "-",
                            "carved",
                            "design",
                            "impressed",
                            "the",
                            "visitors",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 6,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "The",
                            "cozy",
                            ",",
                            "well",
                            "-",
                            "furnished",
                            "office",
                            "accommodated",
                            "many",
                            "employees",
                            "."
                        ],
                        "predicate_index": 7,
                        "target_index": 6,
                        "target_SRL": "ARG0"
                    },
                    {
                        "tokenized": [
                            "At",
                            "dawn",
                            ",",
                            "the",
                            "stunning",
                            ",",
                            "breathtaking",
                            "vista",
                            "left",
                            "everyone",
                            "speechless",
                            "."
                        ],
                        "predicate_index": 8,
                        "target_index": 7,
                        "target_SRL": "ARG0"
                    }
                ]
            }
        },
        "predicatedis": {
            "specialDIR": {
                "1": [
                    {
                        "tokenized1": [
                            "He",
                            "assembled",
                            "enemies",
                            "into",
                            "a",
                            "united",
                            "group",
                            "."
                        ],
                        "tokenized2": [
                            "John",
                            "'s",
                            "assembly",
                            "of",
                            "the",
                            "furniture",
                            "from",
                            "a",
                            "kit",
                            "to",
                            "a",
                            "home",
                            "."
                        ],
                        "predicate_index1": 1,
                        "predicate_index2": 2,
                        "SRL": "ARG4"
                    },
                    {
                        "tokenized1": [
                            "The",
                            "dog",
                            "heeled",
                            "to",
                            "me",
                            "in",
                            "obedience",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "heeled",
                            "the",
                            "bike",
                            "over",
                            "."
                        ],
                        "predicate_index1": 2,
                        "predicate_index2": 1,
                        "SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "John",
                            "forwent",
                            "to",
                            "the",
                            "circus",
                            "."
                        ],
                        "tokenized2": [
                            "Benefits",
                            "are",
                            "forgone",
                            "to",
                            "the",
                            "private",
                            "sector",
                            "."
                        ],
                        "predicate_index1": 1,
                        "predicate_index2": 2,
                        "SRL": "ARG3"
                    },
                    {
                        "tokenized1": [
                            "She",
                            "picked",
                            "at",
                            "her",
                            "pasta",
                            "from",
                            "the",
                            "plate",
                            "."
                        ],
                        "tokenized2": [
                            "You",
                            "ca",
                            "n't",
                            "pick",
                            "grapes",
                            "from",
                            "thornbushes",
                            "."
                        ],
                        "predicate_index1": 1,
                        "predicate_index2": 3,
                        "SRL": "ARG2"
                    },
                    {
                        "tokenized1": [
                            "John",
                            "stresses",
                            "about",
                            "environmental",
                            "awareness",
                            "."
                        ],
                        "tokenized2": [
                            "He",
                            "was",
                            "stressed",
                            "about",
                            "the",
                            "test",
                            "."
                        ],
                        "predicate_index1": 1,
                        "predicate_index2": 2,
                        "SRL": "ARG3"
                    },
                    {
                        "tokenized1": [
                            "We",
                            "cut",
                            "a",
                            "truce",
                            "with",
                            "them",
                            "for",
                            "peace",
                            "."
                        ],
                        "tokenized2": [
                            "Google",
                            "cut",
                            "its",
                            "price",
                            "to",
                            "five",
                            "dollars",
                            "."
                        ],
                        "predicate_index1": 1,
                        "predicate_index2": 1,
                        "SRL": "ARG4"
                    }
                ]
            }
        }
    }
}